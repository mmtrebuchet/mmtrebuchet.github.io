Programs
========

Main CLI
--------

These are the core programs of BPReveal. Each one takes a JSON configuration file.

:py:mod:`interpretFlat<bpreveal.interpretFlat>`
    Generates shap scores of the same type as
    BPNet.
    Hypothetical contributions for each base are written to a
    modisco-compatible h5.

:py:mod:`interpretPisa<bpreveal.interpretPisa>`
    Runs an all-to-all shap analysis on the
    given bed regions or fasta sequences.

:py:mod:`makePredictions<bpreveal.makePredictions>`
    Takes a trained model (solo, combined,
    residual, or even transformation models work) and predicts over the
    given regions.

:py:mod:`motifScan<bpreveal.motifScan>`
    Scan the genome for patterns of contribution
    scores that match motifs identified by modiscolite.

:py:mod:`motifSeqletCutoffs<bpreveal.motifSeqletCutoffs>`
    Loads the output from
    ``modiscolite`` and calculates cutoff values to use during motif
    scanning.

:py:mod:`prepareBed<bpreveal.prepareBed>`
    Given a set of regions and data tracks, reject
    regions that have too few (or too many) reads, or that have unmapped
    bases in the genome.

:py:mod:`prepareTrainingData<bpreveal.prepareTrainingData>`
    Takes in bed and bigwig files and a
    genome, and generates an hdf5-format file containing the samples used
    for training.

:py:mod:`trainCombinedModel<bpreveal.trainCombinedModel>`
    Takes a transformation model and
    experimental data and builds a model to explain the residuals.
    Saves both a combined model and the residual model alone to disk.

:py:mod:`trainSoloModel<bpreveal.trainSoloModel>`
    Takes in a training input configuration
    and trains up a model to predict the given data, with no bias
    correction.
    Saves the model to disk, along with information from the training phase.

:py:mod:`trainTransformationModel<bpreveal.trainTransformationModel>`
    Takes in a bias (i.e., solo)
    model and the actual experimental (i.e., biology + bias) data.
    Derives a relation to best fit the bias profile onto the experimental
    data.
    Saves a new model to disk, adding a simple layer or two to do the
    regression.

Utility CLI
-----------

These are little tools and utilities that help in dealing with models. These
take arguments on the command line.

:py:mod:`lengthCalc<bpreveal.lengthCalc>`
    Given the parameters of a network, like input
    filter width, number of layers &c., determine the input width or
    output width.

:py:mod:`makeLossPlots<bpreveal.makeLossPlots>`
    Once you've trained a model, you can run
    this on the history file to get plots of all of the components of the
    loss.

:py:mod:`metrics<bpreveal.metrics>`
    Calculates a suite of metrics about how good a model's predictions are.

:py:mod:`motifAddQuantiles<bpreveal.motifAddQuantiles>`
    Takes the output from
    :py:mod:`motifScan<bpreveal.motifScan>` and adds quantile information for determining how
    good your motif matches were.

:py:mod:`predictToBigwig<bpreveal.predictToBigwig>`
    Takes the hdf5 file generated by the predict step and converts one track
    from it into a bigwig file.

:py:mod:`shapToBigwig<bpreveal.shapToBigwig>`
    Converts a shap hdf5 file (from
    :py:mod:`interpretFlat<bpreveal.interpretFlat>`) into a bigwig track for
    visualization.

:py:mod:`shapToNumpy<bpreveal.shapToNumpy>`
    Takes the interpretations from
    :py:mod:`interpretFlat<bpreveal.interpretFlat>` and converts them to numpy
    arrays that can be read in by modiscolite.

:py:mod:`checkJson<bpreveal.checkJson>`
    Take a json file and make sure that it's valid input for one of the
    BPReveal programs. Can also be used to identify which BPReveal program a
    json belongs to.

:py:mod:`showTrainingProgress<bpreveal.showTrainingProgress>`
    Read in the log files generated by the training programs (when verbosity is
    ``INFO`` or ``DEBUG`` and show you how well the model's doing in real time.

:py:mod:`showModel<bpreveal.showModel>`
    (DEPRECATED, will be removed in 6.0.0) Make a pretty picture of your model.


API
---
These are Python libraries that do most of the heavy lifting, and can be imported
to do useful things in your code.


:py:mod:`gaOptimize<bpreveal.gaOptimize>`
    contains tools for evolving sequences that lead to desired profiles. It
    implements a genetic algorithm that supports insertions and deletions.

:py:mod:`utils<bpreveal.utils>`
    Contains general-use utilities and a high-performance tool to generate
    predictions for many sequences.

:py:mod:`bedUtils<bpreveal.bedUtils>`
    Useful functions for manipulating bed files, particularly for tiling the
    genome with regions.

:py:mod:`motifUtils<bpreveal.motifUtils>`
    Functions for dealing with motif scanning and modisco files.

:py:mod:`logUtils<bpreveal.logUtils>`
    Functions used to log information. It's basically TensorFlow's wrapper
    around the ``logging`` module in the standard library.

:py:mod:`interpretUtils<bpreveal.interpretUtils>`
    Functions for getting interpretation scores. Contains a streaming system
    for calculating pisa and flat importance scores.

:py:mod:`schema<bpreveal.schema>`
    A set of JSON schemas that validate the inputs to the BPReveal programs.
    These are used to make sure that incorrect inputs trigger errors early, and
    that those errors are clearer to the user.

:py:mod:`training<bpreveal.training>`
    A very simple module that actually runs the training loop for
    :py:mod:`trainSoloModel<bpreveal.trainSoloModel>`,
    :py:mod:`trainTransformationModel<bpreveal.trainTransformationModel>`, and
    :py:mod:`trainCombinedModel<bpreveal.trainCombinedModel>`.

:py:mod:`jaccard<bpreveal.jaccard>`
    Contains wrappers around C functions that calculate the sliding Jaccard similarity
    used to scan for motifs.

:py:mod:`ushuffle<bpreveal.ushuffle>`
    A wrapper around the ushuffle library, used to perform shuffles of sequences that
    preserve k-mer distributions.

Tools
-----

These are miscellaneous programs that are not part of BPReveal proper, but that
I have found useful. They are not actively maintained, and tend to have subpar
documentation.
